<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="viewport" content="width=800">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    .hp-photo{ width:240px; height:240px; border-radius:240px; -webkit-border-radius:240px; -moz-border-radius:240px; }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 24px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
    .center {
        display: block;
        margin-left: auto;
        margin-right: auto;
        width: 70%;
    }
    </style>

    <title>YANG Lei | Homepage </title>
    <!--<link rel="stylesheet" type="text/css" href="/imgs/css" >-->
    <link rel="icon" type="image/jpg" href="./imgs/icon.png">
</head>

<body>
<table width="1000" border="0" align="center" cellspacing="0" cellpadding="0">
<tbody>
<tr>
<td>

    <!--SECTION 1 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td width="68%" valign="middle">
                <p align="center"><name>YANG Lei 杨 磊</name></p>
                <p align="justify">
                    My name is YANG Lei (pronounced "Young Lay," with slightly different tones).
                </p>
                <p align="justify">
                    I am a lecturer (teaching track) at <a href="https://innoacademy.engg.hku.hk/">Tam Wing Fan Innovation Wing (InnoWing)</a>, Faculty of Engineering, The University of Hong Kong.
                </p>
                <p align="justify">
                    I design and develop extracurricular, experiential learning activities for undergraduates to gain real-world engineering experiences.
                    I also supervise a number of undergraduate student projects in the areas of robotics, computer vision, computer graphics, and deep learning.
                    It is much fun to work with brilliant young minds and inspiring teachers.
                </p>
                <p align="justify">
                    My research interests include geometric modeling, robotics, and engineering education.
                </p>
                <p align="justify">
                    I love playing football and I play for HKU staff team.
                </p>
                </br>
                </p><p align="center">
                    <a href="mailto:lyang125[-at-]hku.hk">Email</a> / 
                    <a href="https://scholar.google.com/citations?user=JAzFhXQAAAAJ&hl=en">Google Scholar</a> /
                    <a href="https://github.com/LeiYangJustin">Github</a> /
                    <a href="https://www.linkedin.com/in/lei-yang-842052119/">LinkedIn</a>
                </p>
              </td>
              <td align="right"> <img class="hp-photo" src="./imgs/yanglei_profile.jpeg" onmouseover="this.src='./imgs/mobile_robot.jpg'" onmouseout="this.src='./imgs/yanglei_profile.jpeg'" style="width: 240;"></td></tr>
            </tbody>
          </table>

    <!-- SECTION 2 -->
     <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <td><heading> Work Experience </heading>
          </td>
          </tr></tbody>
    </table>
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tbody><tr>
            <td width="100%" valign="top">
                <p align="justify" style="font-size:16px">
                    Lecturer, Tam Wing Fan Innovation Wing, The University of Hong Kong, 2023-present<br>
                    Research Officer, InnoHK Centre for Transformative Garment Production, 2021-2023<br>
                    Postdoctoral Fellow, Dept. of Computer Science, The University of Hong Kong, 2018-2021<br>
                    Research Assistant, Dept. of Computer Science, The University of Hong Kong, 2016-2017<br>
                </p>
            </td>
        </tr></tbody>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <td><heading> Education </heading>
          </td>
          </tr></tbody>
    </table>
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tbody><tr>
            <td width="100%" valign="top">
                <p align="justify" style="font-size:16px">
                    Ph.D., Automotive Engineering, Dalian University of Technology, 2018<br>
                    B.Eng., Naval Architecture and Ocean Engineering, Dalian University of Technology, 2012
                </p>
            </td>
        </tr></tbody>
    </table>
    
    <!-- SECTION 2 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <td><heading> Student Projects </heading>
          </td>
          </tr></tbody>
    </table> 
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr>
            <td width="50%">
            <img 
                src="./imgs/student_projects/2025_innogrow2.jpg" 
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="100%" valign="top">
	             <p><a href="https://innoacademy.engg.hku.hk/innogrow/">
	             <papertitle>InnoGrow: Smart Weeding Solutions for a Sustainable Future</papertitle></a>
                 <br>Areeya Kongsawangchai, Patt Phurtivilai, Jintao Xie, Chloe Jingjing Gao, Liangyi Chen, Haohua Li
                 <br>
                 <em><a href="https://pitchcomp.hkae.hk/en/results.asp">Winner of HKAE Pitch Competition 2024-2025</a></em>, 
                 <br>
			     <p align="justify" style="font-size:13px">A portable robotic weed control system, named InnoBox, is proposed to enhance the efficiency of agricultural production. 
                    A special thanks to <a href="https://scholar.google.com/citations?user=9KbQJY4AAAAJ&hl=fr">Dr. Michel Dongmo</a> who provided insights and knowledge about farming and weed control to the student team.</p>
                 <strong><font color="green">Robotics</font></strong>
                <p></p>
            </td>
        </tr>

        <tr>
            <td width="50%">
            <img 
                src="./imgs/student_projects/2025_armstrong_hri2025.jpg" 
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <p><a href="https://dl.acm.org/doi/10.5555/3721488.3721817">
	             <papertitle>ArmStrong: An End-user Programming Interface for Robotic Arm Cleaning CNC Machines</papertitle></a>
                 <br>Ian Leong Ting Lo, Bao Guo, Shaoyu Zeng
                 <br>
                 <em>the 2025 ACM/IEEE International Conference on Human-Robot Interaction <br> (Student Design Challenge Track)</a></em>
                 <br>
			     <p align="justify" style="font-size:13px">This project is stemmed from our collaboration with MTR to promote robotic technologies in the maintanence operation. This project aims to achieve SDGs 4 and 9.</p>
                 <strong><font color="green">Robotics</font></strong>
                <p></p>
            </td>
        </tr>
    </table>

    <!-- SECTION 3 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <td><heading> Publications </heading>
          </td>
          </tr></tbody>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
		<tbody>
        
        <tr>
            <td width="50%">
            <img 
                src="./imgs/publications/2025_ASEE_AI_makerspace.png" 
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <!-- <p><a href="https://dl.acm.org/doi/pdf/10.1145/3660348"> -->
	             <papertitle>Equipping Academic Makerspaces with Artificial Intelligence Elements</papertitle></a>
                 <br><strong>Lei Yang</strong>, Tien-Hsuan Wu, Chun Kit Chui, Chun Kit Chan
                 <br>
                 <em>2025 ASEE Annual Conference & Exposition</em>, Montreal, Canada, 2025
                 <br>
			     <p align="justify" style="font-size:13px">
                    We report a sustainable and scalable framework implemented in InnoWing during the past two years for incorporating AI into our academic makerspace. 
                    To make this framework reproducible in other academic makerspaces, we made 
                    <a href="https://summer-cover-169.notion.site/InnoWing-Workshop-Homepage-15ac652096f280708beff277528508c0">our teaching materials</a> 
                    open-sourced. We aim to build an open community for building the next-generation academic makerspaces with AI.
                </p>
                 <strong><font color="red">Engineering education</font></strong>
                <p></p>
            </td>
        </tr>

        <tr>
            <td width="50%">
            <img 
                src="./imgs/publications/2025_ASEE_HKUIW_MTROTD.png" 
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <!-- <p><a href="https://dl.acm.org/doi/pdf/10.1145/3660348"> -->
	             <papertitle>An Experiential Learning Framework to Harvest Synergy from College and Industry Partnership</papertitle></a>
                 <br><strong>Lei Yang</strong>, Chun Kit Chan, Kin Sun Lam, Chun Kit Chui
                 <br>
                 <em>2025 ASEE Annual Conference & Exposition</em>, Montreal, Canada, 2025
                 <br>
			     <p align="justify" style="font-size:13px">
                    Showcasing an industrial collaboration project between InnoWing and MTR Operational Training Centre on hands-on learning of robotic arms for both undergraduate students and industrial professionals.
                </p>
                 <strong><font color="red">Engineering education</font></strong>
                <p></p>
            </td>
        </tr>

        <tr>
            <td width="50%">
            <img 
                src="./imgs/publications/2024_AI_learning.jpg" 
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <p><a href="https://www.google.com/url?sa=i&url=https%3A%2F%2Fpeer.asee.org%2Fempowering-students-in-emerging-technology-a-framework-for-developing-hands-on-competency-in-generative-ai-with-ethical-considerations.pdf&psig=AOvVaw3RiJnup8tf3ILzXDiQM55r&ust=1752336179874000&source=images&cd=vfe&opi=89978449&ved=0CAYQrpoMahcKEwjQt_qYl7WOAxUAAAAAHQAAAAAQBA">
	             <papertitle>A Framework for Developing Hands-on Competency in Generative AI with Ethical Considerations</papertitle></a>
                 <br>Chun Kit Chui, <strong>Lei Yang</strong>, Ben Kao
                 <br>
                 <em>2024 ASEE Annual Conference & Exposition</em>, Portland, USA, 2024
                 <br>
			     <p align="justify" style="font-size:13px">
                    We introduce a progressive framework consisting of three stages: adoption, development, and application of AI competencies. 
                    This framework, implemented at InnoWing, aims to enhance AI literacy and promote responsible AI use. 
                 </p>
                 <strong><font color="red">Engineering education</font></strong>
                <p></p>
            </td>
        </tr>


        <tr>
            <td width="50%">
            <img 
                src="./imgs/publications/2025_NeuPPS.png" 
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <p><a href="https://arxiv.org/pdf/2309.09911">
	             <papertitle>Neural Parametric Surfaces for Shape Modeling</papertitle></a>
                 <br><strong>Lei Yang*</strong>, Yongqing Liang*, Xin Li, Congyi Zhang, Guying Lin, Alla Sheffer, Scott Schaefer, John Keyser, Wenping Wang
                 <br>
                 <em>under review</em>, 2025 
                 <br>
			     <p align="justify" style="font-size:13px">
                    Surface shapes carry design-specific semantics that entail patch layouts consisting of n-gons.
                    We present the first neural piecewise parametric surface with high flexibility to model surface shapes with multiple n-gons.</p>
                 <strong><font color="blue">Geometric modeling</font></strong>
                <p></p>
            </td>
        </tr>
        
        <tr>
            <td width="50%">
            <img 
                src="./imgs/publications/2025_Guying_PatchGrid_TOG2025.png" 
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <p><a href="https://dl.acm.org/doi/pdf/10.1145/3727142">
	             <papertitle>Patch-Grid: an Efficient and Feature-preserving Neural Implicit Surface Representation</papertitle></a>
                 <br>Guying Lin*, <strong>Lei Yang*</strong>, Congyi Zhang, Hao Pan, Yuhan Ping, Guodong Wei, Taku Komura, John Keyser, Wenping Wang
                 <br>
                 <em>ACM Transactions on Graphics</em>, 2025 
                 <br>
			     <p align="justify" style="font-size:13px">
                    A compositional neural implicit representation for modeling sharp geometric features and open surfaces in a few seconds.</p>
                 <strong><font color="blue">Geometric modeling</font></strong>
                <p></p>
            </td>
        </tr>

        <tr>
            <td width="50%">
            <img 
                src="./imgs/publications/2024_Yunhai_FabricAlign_RAL.gif" 
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <p><a href="https://ieeexplore.ieee.org/document/10723787">
	             <papertitle>Efficient Planar Fabric Repositioning: Deformation-Aware RRT* for Non-Prehensile Fabric Manipulation</papertitle></a>
                 <br>Yunhai Wang, <strong>Lei Yang</strong>, Peng Zhou, Jiaming Qi, Liang Lu, Jihong Zhu, Jia Pan
                 <br>
                 <em>IEEE Robotics and Automation Letters</em>, 2024
                 <br>
			     <p align="justify" style="font-size:13px">Humans are good at using fingers to push, drag, or fling fabric pieces around.
                    We present a method to plan a series of non-prehensile actions to align a fabric piece to specified goal pose. 
                 </p>
                 <strong><font color="green">Robotics</font></strong>
                <p></p>
            </td>
        </tr>

        <tr>
            <td width="50%">
            <img 
                src="./imgs/publications/2024_linhan_wafr2024.gif"
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <p><a href="https://algorithmic-robotics.org/papers/86_One_Fling_to_Goal_Environme.pdf">
	             <papertitle>One Fling to Goal: Environment-aware Dynamics for Goal-conditioned Fabric Flinging</papertitle></a>
                 <br>Linhan Yang, <strong>Lei Yang</strong>,  Haoran Sun, Zeqing Zhang, Haibin He, Fang Wan, Chaoyang Song, Jia Pan
                 <br>
                 <em>The 16th International Workshop on the Algorithmic Foundations of Robotics (WAFR)</em>, 2024 
                 <br>
			     <p align="justify" style="font-size:13px">Humans are good at using fingers to push, drag, or fling fabric pieces around.
                    This paper presents an approach to flinging a fabric object to a target position in a single attempt by modeling the fabric dynamics with environments.</p>
                 <strong><font color="green">Robotics</font></strong>
                <p></p>
            </td>
        </tr>

        <tr>
            <td width="50%">
            <img 
                src="./imgs/publications/2024_ruixing_hri2024.png" 
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <p><a href="https://dl.acm.org/doi/pdf/10.1145/3660348">
	             <papertitle>Learning Autonomous Viewpoint Adjustment from Human Demonstrations for Telemanipulation</papertitle></a>
                 <br>Ruixing Jia, <strong>Lei Yang</strong>, Ying Cao, Calvin Kalun Or, Wenping Wang, Jia Pan
                 <br>
                 <em>ACM Transactions on Human-Robot Interaction</em>, 2024 
                 <br>
			     <p align="justify" style="font-size:13px">
                    It is mentally and physically demanding for an operator to controll both the robotic manipulator and the remote camera in a teleoperation setting.
                    We present an autonomous viewpoint adjustment system to allow human operators to focus on controlling only the remote manipulator.</p>
                 <strong><font color="green">Human-robot interaction</font></strong>
                <p></p>
            </td>
        </tr>

        <tr>
            <td width="50%">
            <img 
                src="./imgs/publications/2024_Guying_MLP_Freq_TVCG2025.png"
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <p><a href="https://ieeexplore.ieee.org/document/10815066">
	             <papertitle>On Optimal Sampling for Learning SDF Using MLPs Equipped with Positional Encoding</papertitle></a>
                 <br>Guying Lin*, <strong>Lei Yang*</strong>, Yuan Liu, Congyi Zhang, Junhui Hou, Xiaogang Jin, Taku Komura, John Keyser, Wenping Wang
                 <br>
                 <em>IEEE Transactions on Visualization and Computer Graphics</em>, 2024 
                 <br>
			     <p align="justify" style="font-size:13px">The intrinisc frequecy of MLP neural networks of the same architecture is demonstrated. 
                    Interplay of the intrinsic frequency and artifacts in learned SDF with sinusoidal positional encoding 
                    can be empirically explained by the Nyquist-Shannon sampling theorem.</p>
                 <strong><font color="blue">Geometric modeling</font></strong>
                <p></p>
            </td>
        </tr>

        <tr>
            <td width="50%">
            <img 
                src="./imgs/publications/2024_RSS_Guanqi_LASP.png" 
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <p><a href="https://arxiv.org/pdf/2407.09792">
	             <papertitle>Language-augmented Symbolic Planner for Open-world Task Planning</papertitle></a>
                 <br>Guanqi Chen, <strong>Lei Yang</strong>, Ruixing Jia, Zhe Hu, Yizhou Chen, Wei Zhang, Wenping Wang, Jia Pan
                 <br>
                 <em>Robotics: Science and Systems</em>, Chicago, USA, 2024
                 <br>
			     <p align="justify" style="font-size:13px">A symbolic planner augmented with an LLM to supplement commonsense for long-horizon task planning and action recorrection.</p>
                 <strong><font color="green">Robotics</font></strong>
                <p></p>
            </td>
        </tr>

        <tr>
            <td width="50%">
            <img 
                src="./imgs/publications/2022_Congyi_CreatureShop_TVCG2022.png"
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <p><a href="https://ieeexplore.ieee.org/document/9852696">
	             <papertitle>Creatureshop: Interactive 3d character modeling and texturing from a single color drawing</papertitle></a>
                 <br>Congyi Zhang, <strong>Lei Yang</strong>, Nenglun Chen, Nicholas Vining, Alla Sheffer, Francis CM Lau, Guoping Wang, Wenping Wang
                 <br>
                 <em>IEEE Transactions on Visualization and Computer Graphics</em>, 2022
                 <br>
			     <p align="justify" style="font-size:13px">An interactive UI for modeling 3D characters and texturing them from a single color drawing.</p>
                 <strong><font color="blue">Geometric modeling</font></strong>
                <p></p>
            </td>
        </tr>

        <tr>
            <td width="50%">
            <img 
                src="./imgs/publications/2022_Weilin_HRC_RAL2022.png"
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <p><a href="https://arxiv.org/pdf/2206.12612">
	             <papertitle>Learn to predict how humans manipulate large-sized objects from interactive motions</papertitle></a>
                 <br>Weilin Wan, <strong>Lei Yang</strong>, Lingjie Liu, Zhuoying Zhang, Ruixing Jia, Yi-King Choi, Jia Pan, Christian Theobalt, Taku Komura, Wenping Wang
                 <br>
                 <em>IEEE Robotics and Automation Letters</em>, 2022
                 <br>
			     <p align="justify" style="font-size:13px">A deep learning method and a <a href="https://github.com/HiWilliamWWL/Learn-to-Predict-How-Humans-Manipulate-Large-Sized-Objects-From-Interactive-Motions-objects">dataset</a> for human whole-body manipulation of large-sized objects</p>
                 <strong><font color="green">Human-robot interaction</font></strong>
                <p></p>
            </td>
        </tr>

        <tr>
            <td width="50%">
            <img 
                src="./imgs/publications/2020_Yilin_Edge6DPose_RAL.png"
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <p><a href="https://ieeexplore.ieee.org/document/9126189">
	             <papertitle>Edge enhanced implicit orientation learning with geometric prior for 6D pose estimation</papertitle></a>
                 <br>Yilin Wen, Hao Pan, <strong>Lei Yang</strong>, Wenping Wang
                 <br>
                 <em>IEEE Robotics and Automation Letters</em>, 2020
                 <br>
			     <p align="justify" style="font-size:13px">
                    Estimating 6D poses of CAD objects with no texture and high symmetry from RGB images is an important but challenging task.
                    A geometric prior is enforced such that the encoded representations of two images are closer in the latent space if their corresponding poses are closer in SE(3).
                 </p>
                 <strong><font color="blue">Deep learning for geometry</font></strong>
                <p></p>
            </td>
        </tr>

        <tr>
            <td width="50%">
            <img 
                src="./imgs/publications/2020_Mine_Sinkhorn_Corresp_ECCV2020.png"
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <p><a href="https://arxiv.org/pdf/2007.09594">
	             <papertitle>Mapping in a cycle: Sinkhorn regularized unsupervised learning for point cloud shapes</papertitle></a>
                 <br><strong>Lei Yang</strong>, Wenxi Liu, Zhiming Cui, Nenglun Chen, Wenping Wang
                 <br>
                 <em>European Conference on Computer Vision</em>, Edinburgh, UK, 2020 (Virtual)
                 <br>
			     <p align="justify" style="font-size:13px">Unsupervised learning of point-wise feature descriptors for objects with dense correspondence as the pretext. 
                    Sinkhorn regularization is used to enforce the bijective map between the same object under different poses during the training.</p>
                 <strong><font color="blue">Deep learning for geometry</font></strong>
                <p></p>
            </td>
        </tr>

        <tr>
            <td width="50%">
            <img 
                src="./imgs/publications/2018_JMD.png" 
                alt="PontTuset" 
                class="center" 
                style="max-width: 50%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <p><a href="https://asmedigitalcollection.asme.org/mechanicaldesign/article-abstract/140/12/121404/366180/Skeleton-Section-Template-Parameterization-for">
	             <papertitle>Skeleton-Section Template Parameterization for Shape Optimization</papertitle></a>
                 <br>Ping Hu, <strong>Lei Yang</strong>, Baojun Li
                 <br>
                 <em>Journal of Mechanical Design</em>, 2018
                 <br>
			     <p align="justify" style="font-size:13px">A parameterization method based on the Skeleton-Section template for optimizing thin-walled structures under crash loading.</p>
                 <strong><font color="blue">Computer-aided design</font></strong>
                <p></p>
            </td>
        </tr>

        <tr>
            <td width="50%">
            <img 
                src="./imgs/publications/2016_CAD.png" 
                alt="PontTuset" 
                class="center" 
                style="max-width: 70%; height: auto; border-style: none;">
            </td>
            <td width="80%" valign="top">
	             <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0010448515001621">
	             <papertitle>Finite element mesh deformation with the skeleton-section template</papertitle></a>
                 <br><strong>Lei Yang</strong>, Baojun Li, Zhangquan Lv, Wenbin Hou, Ping Hu
                 <br>
                 <em>Computer-Aided Design</em>, 2016
                 <br>
			     <p align="justify" style="font-size:13px">A radial basis function-based deformation method for finite element mesh of thin-walled structures using the curve skeleton and cross-sectional profiles as hierarchical deformation handles.</p>
                 <strong><font color="blue">Computer-aided design</font></strong>
                <p></p>
            </td>
        </tr>



    </tbody>
    </table>
    <p align="justify">* denotes equal contribution. Please see my <a href="https://scholar.google.com/citations?user=JAzFhXQAAAAJ&hl=en">google scholar page</a> for full list of publications.</p>  

    <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
        <td width="100%" align="middle">
        <p align="center" style="width: 25% ">
            <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=QEkmF-C42WJ7pgdkzHfymqAurNhoQUVlKjDixPBGUPQ"></script>
        </p></td>
        </tr>
        </tbody>
        </table> -->

    <!--SECTION 10 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
         <tbody><tr>
            <td><br>
               <!--<p align="right"><font size="3">Erd&ouml;s = ? </font><br> -->
		       <p align="right"><font size="2"> Last update: 2025.07. <a href="http://www.cs.berkeley.edu/~barron/">Thanks.</a></font></p>
            </td>
         </tr>
         </tbody>
     </table>


</td>
</tr>
</tbody>
</table>
</body>
</html>
